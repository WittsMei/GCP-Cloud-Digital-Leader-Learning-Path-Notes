# GCP-Notes

## Databases, Data Warehouses, and Data Lakes

### üß† Combined Architectures in the Modern Data Stack ###
In modern data architectures, organizations typically combine Databases, Data Warehouses, and Data Lakes to support operational efficiency, business intelligence, and advanced analytics such as machine learning.

**1Ô∏è‚É£ Databases ‚Äì Real-Time Operational Layer**
- Store structured, transactional data generated by operational systems (e.g., apps, websites, CRMs).

- Designed for OLTP (Online Transaction Processing).

- Optimized for fast reads/writes, ACID compliance, and real-time performance.

- Examples: PostgreSQL, MySQL, MongoDB, Cloud SQL, AWS RDS

**2Ô∏è‚É£ ETL / ELT Tools ‚Äì Data Movement & Transformation Layer**
- Extract data from databases and load into downstream systems.

- Perform transformations either: Before loading (ETL ‚Äì Extract, Transform, Load), or After loading (ELT ‚Äì Extract, Load, Transform).

- Enable data quality checks, lineage tracking, and orchestration.

- Examples: Apache Airflow, dbt, Fivetran, Airbyte, Talend

**3Ô∏è‚É£ Data Warehouses ‚Äì Business Intelligence Layer**
- Centralize structured, cleaned, and joined data optimized for analytics.

- Enable dashboards, KPI tracking, and trend analysis through OLAP (Online Analytical Processing).

- Store both current and historical data for time-series analysis and forecasting.

- Examples: Google BigQuery, Snowflake, Amazon Redshift, Azure Synapse

**4Ô∏è‚É£ Data Lakes ‚Äì Raw Data and Advanced Analytics Layer**
- Store all data ‚Äî structured, semi-structured, and unstructured ‚Äî in its native/raw form.

- Cost-effective and scalable for massive datasets.

- Ideal for data science, machine learning, and data exploration.

- Use schema-on-read instead of strict upfront schema definitions.

- Examples: AWS S3, Azure Data Lake Storage, Google Cloud Storage

**5Ô∏è‚É£ Query Engines over Data Lakes**
- Provide SQL-based querying capabilities directly on data lake files without the need for data movement.

- Bridge the gap between raw storage and actionable insights.

- Common in serverless or ad hoc analytics scenarios.

- Examples: Presto, Trino, Amazon Athena, Google BigLake, Databricks SQL

![image](https://github.com/user-attachments/assets/37edb1c5-dc72-4864-9be2-c7c8793dc3ea)


## First, Second, and Third Party Data 

**1Ô∏è‚É£ First-Party Data ‚Äì Your Own Data**
- Definition: Data you collect directly from your customers, users, or audience through your own channels.

- Sources: Website analytics (via cookies or user activity), Mobile apps, CRM systems, Subscription forms, Purchase history, Customer surveys, Support tickets or chat interactions

- Example: A user logs into your e-commerce site and buys a product. The behavior, purchase history, and profile data are first-party data.

**2Ô∏è‚É£ Second-Party Data ‚Äì Someone Else‚Äôs First-Party Data (Shared)**
- Definition: Data that another organization collects directly from its users (i.e., their first-party data), but shares or sells directly to you through a partnership.

- Sources: Strategic data-sharing agreements, Data co-ops, Publishers or retailers with overlapping customer bases

- Example: An airline shares customer loyalty data with a hotel chain for a joint loyalty rewards campaign. The hotel is using second-party data from the airline.


**3Ô∏è‚É£ Third-Party Data ‚Äì Aggregated Data from External Sources**
- Definition: Data collected by entities that don‚Äôt have a direct relationship with the users. It‚Äôs aggregated from various sources and sold through data brokers or platforms.

- Sources: Data aggregators and brokers (e.g., Acxiom, Oracle Data Cloud), Public records, cookies, SDKs, Surveys, social media scraping, publisher networks

- Example: A media buying platform buys demographic and behavioral data from a data broker to run a digital ad campaign. That‚Äôs third-party data.


## Data value chain
### üîÅ The Modern Data Lifecycle
**(Data Genesis ‚Üí Collection ‚Üí Processing ‚Üí Storage ‚Üí Analysis ‚Üí Activation)**


**1Ô∏è‚É£ Data Genesis ‚Äì Where It All Begins**
- Definition: The origin or creation of data ‚Äî the moment something is recorded, sensed, entered, or generated.

- Sources: User interactions (clicks, forms, transactions), Machine-generated logs (IoT devices, sensors), Software systems (CRMs, ERPs), Public or third-party APIs, External datasets (social media, open data portals)


**2Ô∏è‚É£ Data Collection ‚Äì Capturing the Raw Inputs**
- Definition: The process of capturing and gathering data from its point of origin.

- Methods: Web tracking (e.g., pixels, cookies), API ingestion, Log streaming (e.g., via Kafka), Batch uploads (CSV, JSON, etc.), Surveys, forms, manual entry


**3Ô∏è‚É£ Data Processing ‚Äì Cleaning, Enriching, Shaping**
- Definition: Raw data is transformed into usable formats ‚Äî cleaned, validated, and enriched.

- Tasks: Data cleaning (remove duplicates, handle nulls), Format conversion (e.g., JSON ‚Üí Parquet), Enrichment (e.g., adding geolocation or metadata), Validation and standardization

**4Ô∏è‚É£ Data Storage ‚Äì Organized and Persistent Holding**
- Definition: Processed data is stored in centralized systems optimized for querying and analysis.

- Types of Storage: Data Warehouses (structured, analytics-ready), Data Lakes (raw, semi/unstructured), Lakehouses (hybrid approach)

**5Ô∏è‚É£ Data Analysis ‚Äì Turning Data Into Insight**
- Definition: Data is explored, queried, modeled, or visualized to extract meaning or detect patterns.

- Activities: Descriptive analytics (dashboards, reporting), Diagnostic analytics (why did it happen?), Predictive analytics (what will happen?), Prescriptive analytics (what should be done?)

**6Ô∏è‚É£ Data Activation ‚Äì Turning Insights into Action**
- Definition: Operationalizing data by integrating it into decision-making systems, applications, or user experiences.

- Forms of Activation: Personalization (recommendation systems), Automated workflows (email, ads, alerts), Decision support (dashboards for business users), ML deployment (real-time predictions)


## Why ML Model requires high-quality data
- An ML model cannot make accurate predictions by learning from incorrect data

**To assess it's quality, data is evaluated against six dimensions**

- Completeness: The completeness of data refers to whether all the required information is present.
- Uniqueness: Data should be unique. If a model is trained on a data set with a high number of duplicates, the ML model may not be able to learn accurately.
- Timeliness: The timeliness of the data refers to whether the data is up-to-date and reflects the current state of the phenomenon that's being modeled.
- Validity: Validity means the data conforms to a set of predefined standards and definitions, such as type and format. Validity also ensures that data is in an acceptable range.
- Accuracy: Accuracy reflects the correctness of the data.
- Consistency: The consistency of the data refers to whether the data is uniform and doesn't contain any contradictory information.


## ML options on Google Cloud
- BigQuery ML
- Pre-trained APIs
- AutoML
- Custom training
![Screenshot 2025-05-11 013654](https://github.com/user-attachments/assets/99dee475-cb2e-41e2-aed6-e0d3cd7af281)



## Considerations when selecting a Google Cloud AI/ML solutions
- Speed
- Differentiation
- Expertise
- Effort


## Cloud change patterns
- Move applications first and then change them
- Change applications before they move
- Invest in greenfield (Build entirely new applications in the cloud)
- Invest in brownfield (Work with existing legacy systems, either by migrating or integrating them with new cloud systems)
- Move applicaitons without any changes


## Key security terms and concepts
- Privileged access: Grants specific users access to a broader set of resources than ordinary users. (eg: a system administrator)
- Least privilege: Advocates granting users only the access they need to perform their job responsibilities. (eg: Sales representative only have the access to CRM system)
- Zero-trust architecture: Assumes that no user or device can be trusted by default


## Three essential aspects of security 
- Confidentiality
- Integrity
- Availability

The CIA triad emphasizes the importance of protecting sensitive information, ensuring data accuracy and trustworthiness, and maintaining uninterrupted access to resources and services.


## Common cybersecurity threats
- Social engineering
- Physical damage
- Malware, Viruses, and Ransomware
- Vulnerable thrid-party systems
- Configuration mishaps



